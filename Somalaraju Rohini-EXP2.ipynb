{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clFgmCs3kI8y",
        "outputId": "5769c4d2-7cab-4d30-f1fb-0739d0fbc19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "        ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
            "0  462809    Male           No   22        No     Healthcare              1.0   \n",
            "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
            "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
            "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
            "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
            "\n",
            "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
            "0            Low          4.0  Cat_4            D  \n",
            "1        Average          3.0  Cat_4            A  \n",
            "2            Low          1.0  Cat_6            B  \n",
            "3           High          2.0  Cat_6            B  \n",
            "4           High          6.0  Cat_6            A  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1579495385.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X[\"Work_Experience\"].fillna(X[\"Work_Experience\"].median(), inplace=True)\n",
            "/tmp/ipython-input-1579495385.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X[\"Family_Size\"].fillna(X[\"Family_Size\"].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 completed\n",
            "Epoch 2/20 completed\n",
            "Epoch 3/20 completed\n",
            "Epoch 4/20 completed\n",
            "Epoch 5/20 completed\n",
            "Epoch 6/20 completed\n",
            "Epoch 7/20 completed\n",
            "Epoch 8/20 completed\n",
            "Epoch 9/20 completed\n",
            "Epoch 10/20 completed\n",
            "Epoch 11/20 completed\n",
            "Epoch 12/20 completed\n",
            "Epoch 13/20 completed\n",
            "Epoch 14/20 completed\n",
            "Epoch 15/20 completed\n",
            "Epoch 16/20 completed\n",
            "Epoch 17/20 completed\n",
            "Epoch 18/20 completed\n",
            "Epoch 19/20 completed\n",
            "Epoch 20/20 completed\n",
            "\n",
            "Training Completed\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1072  630  223  893]\n",
            " [ 610  903  459  436]\n",
            " [ 367  678  999  398]\n",
            " [ 483  234  101 2209]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.42      0.38      0.40      2818\n",
            "           B       0.37      0.38      0.37      2408\n",
            "           C       0.56      0.41      0.47      2442\n",
            "           D       0.56      0.73      0.63      3027\n",
            "\n",
            "    accuracy                           0.48     10695\n",
            "   macro avg       0.48      0.47      0.47     10695\n",
            "weighted avg       0.48      0.48      0.48     10695\n",
            "\n",
            "\n",
            "Sample Prediction: D\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# -----------------------------\n",
        "# Load Dataset\n",
        "# -----------------------------\n",
        "dataset = pd.read_csv(\"customers.csv\")\n",
        "print(\"Dataset Preview:\\n\", dataset.head())\n",
        "\n",
        "# -----------------------------\n",
        "# Separate features & target\n",
        "# -----------------------------\n",
        "X = dataset.drop(\"Segmentation\", axis=1)\n",
        "y = dataset[\"Segmentation\"]\n",
        "\n",
        "# -----------------------------\n",
        "# Handle missing values\n",
        "# -----------------------------\n",
        "X[\"Work_Experience\"].fillna(X[\"Work_Experience\"].median(), inplace=True)\n",
        "X[\"Family_Size\"].fillna(X[\"Family_Size\"].median(), inplace=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Encode categorical columns\n",
        "# -----------------------------\n",
        "cat_cols = X.select_dtypes(include=\"object\").columns\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "\n",
        "# -----------------------------\n",
        "# Encode target\n",
        "# -----------------------------\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# -----------------------------\n",
        "# Scale features\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# -----------------------------\n",
        "# Convert to tensors\n",
        "# -----------------------------\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# -----------------------------\n",
        "# DataLoader (faster settings)\n",
        "# -----------------------------\n",
        "dataset = TensorDataset(X, y)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Neural Network Model\n",
        "# -----------------------------\n",
        "class PeopleClassifier(nn.Module):\n",
        "    def __init__(self, input_size, classes):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = PeopleClassifier(X.shape[1], len(label_encoder.classes_))\n",
        "\n",
        "# -----------------------------\n",
        "# Loss & Optimizer\n",
        "# -----------------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# -----------------------------\n",
        "# Training (reduced epochs)\n",
        "# -----------------------------\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    for xb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(xb)\n",
        "        loss = criterion(outputs, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} completed\")\n",
        "\n",
        "print(\"\\nTraining Completed\")\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation (same data)\n",
        "# -----------------------------\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = torch.argmax(model(X), dim=1)\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y, predictions))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(\n",
        "    y,\n",
        "    predictions,\n",
        "    target_names=label_encoder.classes_,\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "# -----------------------------\n",
        "# Sample Prediction\n",
        "# -----------------------------\n",
        "sample = X[0].unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "    pred = model(sample)\n",
        "    result = label_encoder.inverse_transform([torch.argmax(pred).item()])\n",
        "\n",
        "print(\"\\nSample Prediction:\", result[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5mzOcUDkj8n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}